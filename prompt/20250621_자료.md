# YWLab AI 플랫폼 개발 자료 (2025-06-21)

## 📋 목차
1. [배포 시스템 개선](#배포-시스템-개선)
2. [헬스체크 제거](#헬스체크-제거)
3. [로그 시스템 외부 저장](#로그-시스템-외부-저장)
4. [프론트엔드 구조 개선](#프론트엔드-구조-개선)
5. [헬스체크 API 경로 변경](#헬스체크-api-경로-변경)
6. [오픈소스 LLM 도입 검토](#오픈소스-llm-도입-검토)
7. [RAG 기반 데이터 분석](#rag-기반-데이터-분석)

---

## 🚀 배포 시스템 개선

### 변경 사항
- **헬스체크 제거**: 배포 시간 단축 및 안정성 향상
- **로그 확인 방식**: 헬스체크 대신 Flask 서버 시작 로그 확인
- **접속 URL 정리**: 외부/내부/IP 접속 구분

### 배포 스크립트 개선
```bash
# 기존: 헬스체크로 구동 완료 확인
curl -f http://127.0.0.1:8085/health

# 개선: 로그 확인으로 구동 완료 확인
docker compose logs app | grep "Flask 서버 시작"
```

### 최종 접속 URL
- **외부 접속**: `http://enermind.ywlabs.com`
- **IP 접속**: `http://192.168.0.94:8085`
- **내부 접속**: `http://127.0.0.1:8085`

---

## 🏥 헬스체크 제거

### 제거 이유
- 백엔드 기동 시간이 오래 걸림 (ChromaDB 초기화 등)
- 헬스체크 실패로 인한 불필요한 배포 실패
- 로그 확인 방식이 더 정확함

### 수정된 파일들
- `apply/apply_prod/deploy.sh`
- `apply/apply_prod/deploy-quick.bat`
- `apply/apply_prod/deploy.bat`

### 대체 방법
```bash
# 60초 동안 Flask 서버 시작 메시지 대기
for i in {1..60}; do
    if docker compose logs app | grep -q "Flask 서버 시작"; then
        echo "✅ Flask 서버가 정상적으로 시작되었습니다!"
        break
    fi
    sleep 1
done
```

---

## 📁 로그 시스템 외부 저장

### 로그 경로 설정
```python
# backend/config.py
class ProdConfig(BaseConfig):
    def __init__(self):
        # 로그 설정 (운영 환경 - Docker 볼륨 마운트)
        self.LOG_DIR = '/home/ywlabs04/apps_log/enermind/flask'
        self.LOG_LEVEL = 'INFO'
```

### Docker 볼륨 마운트
```yaml
# docker-compose.yml
volumes:
  - ./logs:/app/backend/logs
  - ./uploads:/app/backend/uploads
```

### 로그 파일 구조
```
/home/ywlabs04/apps_log/enermind/flask/
├── app.log          # 애플리케이션 로그
├── error.log        # 에러 로그
└── access.log       # 접근 로그
```

### 로그 확인 명령어
```bash
# 실시간 로그 모니터링
tail -f /home/ywlabs04/apps_log/enermind/flask/app.log

# 에러 로그 확인
tail -f /home/ywlabs04/apps_log/enermind/flask/error.log

# 최근 로그 확인
tail -20 /home/ywlabs04/apps_log/enermind/flask/app.log
```

---

## 🏗️ 프론트엔드 구조 개선

### 기존 구조 문제
```
/app/backend/frontend/dist/  # 잘못된 경로
```

### 개선된 구조
```
/app/
├── backend/           # Flask 백엔드 소스
│   ├── app.py
│   ├── routes/
│   └── ...
├── frontend/          # 프론트엔드 빌드 결과
│   └── dist/
│       ├── index.html
│       ├── assets/
│       └── ...
└── ...
```

### Dockerfile 수정
```dockerfile
# 프론트엔드 빌드 결과를 올바른 경로에 복사
COPY --from=frontend-build /app/frontend/dist ./frontend/dist
```

### Flask 앱 static_folder 설정
```python
# backend/app.py
static_folder = os.path.join(os.path.dirname(__file__), '..', 'frontend', 'dist')
```

---

## 🔗 헬스체크 API 경로 변경

### 변경 사항
- **기존**: `/health`
- **변경**: `/api/health`

### 수정된 파일들
- `backend/app.py`: 라우트 경로 변경
- `apply/apply_prod/docker-compose.yml`: 헬스체크 URL 변경
- `apply/apply_prod/Dockerfile`: 헬스체크 URL 변경
- `apply/conf_nginx/ywlab.conf`: Nginx 설정 변경

### 새로운 헬스체크 URL
- **내부**: `http://127.0.0.1:5000/api/health`
- **외부**: `http://192.168.0.94:8085/api/health`
- **도메인**: `http://enermind.ywlabs.com/api/health`

### 헬스체크 응답 예시
```json
{
  "status": "healthy",
  "timestamp": 1734567890.123,
  "service": "ywlab-backend",
  "version": "1.0.0"
}
```

---

## 🤖 오픈소스 LLM 도입 검토

### 추천 모델들

#### 한국어 특화 모델
1. **KoGPT 계열**
   - KoGPT-2 (SKT): 한국어 최적화
   - 장점: 한국어 자연스러움, 상업적 사용 가능
   - 단점: 모델 크기 제한

2. **Polyglot-Ko**
   - 한국어 특화 모델 (1.3B, 3B, 5.8B)
   - 장점: 한국어 성능 우수
   - 단점: 상대적으로 작은 모델 크기

#### 다국어/영어 모델
1. **Llama 계열**
   - Llama 2/3 (7B, 13B, 70B)
   - 장점: 높은 성능, 다양한 크기
   - 단점: 영어 중심, 한국어 파인튜닝 필요

2. **Mistral 계열**
   - Mistral 7B, Mixtral 8x7B
   - 장점: 효율성 우수, 빠른 추론
   - 단점: 한국어 성능 제한

### LangChain 지원도
- **완전 지원**: Llama 2/3, Mistral, Gemma
- **부분 지원**: KoGPT, Polyglot-Ko (HuggingFace 통합)
- **제한적 지원**: KULLM 등

### YWLab 추천 조합
```python
# 1단계 (시작)
모델: KoGPT-2 (SKT)
이유: 한국어 지원, 구현 쉬움

# 2단계 (발전)
모델: Llama 2 13B + 한국어 파인튜닝
이유: 성능 향상, 확장성

# 3단계 (고도화)
모델: Llama 3 70B + 도메인 특화 파인튜닝
이유: 최고 성능, 완전한 프라이빗 AI
```

### 하드웨어 요구사항
- **7B 모델**: 16GB GPU RAM (최소)
- **13B 모델**: 32GB GPU RAM (권장)
- **70B 모델**: 80GB+ GPU RAM (고성능)

---

## 📊 RAG 기반 데이터 분석

### RAG + 통계 데이터 활용
```python
# 통계 데이터 컬렉션 구성
statistics_collections = [
    {
        "collection": "energy_statistics",
        "type": "statistics",
        "data": [
            "에너지 사용량 월별 평균: 1월 1200kWh, 2월 1100kWh...",
            "피크 시간대: 오전 9-11시, 오후 2-4시",
            "절약 효과: LED 조명 교체 시 15% 절약"
        ]
    }
]
```

### 분석 파이프라인
```python
def analyze_with_statistics(user_query, data_type):
    # 1. 관련 통계 데이터 검색
    relevant_stats = statistics_service.get_relevant_statistics(
        user_query, data_type
    )
    
    # 2. LLM 분석
    prompt = f"""
    관련 통계 데이터:
    {relevant_stats}
    
    분석 요청: {user_query}
    """
    
    return llm(prompt)
```

### 가능한 분석 영역
1. **에너지 데이터 분석**: 사용량 트렌드, 피크 예측
2. **매출 데이터 분석**: 매출 트렌드, 계절성 분석
3. **고객 데이터 분석**: 세그먼트 분석, 이탈 위험 예측

### 장점
- ✅ **정확성 향상**: 사전 통계 데이터 기반
- ✅ **일관성**: 표준화된 통계 정보 활용
- ✅ **실시간 결합**: 현재 데이터와 과거 통계 결합
- ✅ **확장성**: 새로운 통계 데이터 쉽게 추가

---

## 💰 ChatGPT vs 로컬 LLM 비용 비교

### ChatGPT API 비용
- **GPT-3.5-turbo**: $0.002/1K tokens
- **월 사용량 100만 토큰**: $2

### 로컬 LLM 비용
- **GPU 서버**: 월 $500-2000
- **전력비**: 월 $100-300
- **유지보수**: 월 $200-500
- **총 비용**: 월 $800-2800

### ChatGPT 사용 이유
1. **하드웨어 제약**: GPU 서버 없음
2. **개발 속도**: 빠른 구현 가능
3. **비용 효율성**: 소규모 사용 시 저렴
4. **안정성**: 99.9% 가동률
5. **유지보수**: 자동 관리

### 단계별 마이그레이션 계획
1. **1단계**: 현재 (ChatGPT) - 빠른 개발, 안정성
2. **2단계**: 하이브리드 - 중요도에 따른 분리
3. **3단계**: 완전 로컬 - 하드웨어 투자 후

---

## 📚 참고 자료

### 배포 관련
- [Docker Compose 설정](./apply/apply_prod/docker-compose.yml)
- [배포 스크립트](./apply/apply_prod/deploy.sh)
- [README.md](./apply/apply_prod/README.md)

### 개발 관련
- [Flask 앱 설정](./backend/app.py)
- [환경 설정](./backend/config.py)
- [Nginx 설정](./apply/conf_nginx/ywlab.conf)

### 모니터링
- 로그 경로: `/home/ywlabs04/apps_log/enermind/flask/`
- 헬스체크: `http://192.168.0.94:8085/api/health`
- 접속 URL: `http://enermind.ywlabs.com`

---

## 🎯 다음 단계

### 단기 목표
1. ✅ 헬스체크 제거 및 배포 안정화
2. ✅ 로그 시스템 외부 저장 완료
3. ✅ 프론트엔드 구조 개선
4. ✅ 헬스체크 API 경로 통일

### 중기 목표
1. 🔄 RAG 기반 데이터 분석 기능 추가
2. 🔄 위젯 기반 대시보드 확장
3. 🔄 성능 모니터링 시스템 구축

### 장기 목표
1. 🚀 오픈소스 LLM 도입 검토
2. 🚀 완전한 프라이빗 AI 시스템 구축
3. 🚀 고급 데이터 분석 기능 구현

---

*작성일: 2025-06-21*  
*작성자: YWLab 개발팀* 