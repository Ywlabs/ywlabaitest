# 활성 컨텍스트

## 2024-06 최신 시스템 맥락

- **API 표준화:**
  - 모든 백엔드 API가 `{ success, code, message, data, error }` 구조로 통일.
  - 프론트엔드 전체에서 이 구조에 맞춰 데이터 파싱, 에러 처리, UI 렌더링 일관화.
- **공통 컴포넌트:**
  - CommonToast, CommonError, CommonLoading 등 공통 UI 컴포넌트 도입 및 전체 적용.
  - 기존 개별 에러/로딩/토스트 UI 완전 제거.
- **라우트 구조:**
  - 백엔드 라우트 파일을 도메인별로 분리(chat_routes, employee_routes 등)하고, app.py에서 직접 import/register.
- **위젯 구조:**
  - 모든 위젯은 동적 import, 공통 스타일/컴포넌트 적용, UI/UX 일관성 강화.
- **불필요 API 정리:**
  - /api/routes 등 미사용 API 및 관련 코드 완전 삭제.
- **인증/다운로드 기능 계획:**
  - JWT 기반 인증, 사용자별 이력 관리, 채팅 기반 PDF/DOCX 다운로드 기능 설계 중.
- **프론트/백엔드 연동:**
  - 표준화된 API 응답 구조, 공통 컴포넌트, 데이터 구조 일관성 유지.
- **보안/성능/테스트:**
  - 환경 변수, XSS 방지(DOMPurify), 캐시/성능 최적화, 테스트 전략 강화.

## 현재 작업 초점
- 백엔드 `chat_service` 아키텍처 안정화 및 RAG 답변 품질 개선.
- 프롬프트 엔지니어링을 통해 LLM의 출력(특히 Markdown)을 일관성 있게 제어.
- 프론트엔드-백엔드 간 데이터 구조 일관성 확보 및 관련 버그 수정.

## 최근 변경사항
- **`chat_service` 리팩토링 (2-Step Pipeline):**
  1.  `get_db_response`를 통해 정형화된 질문(직원 검색 등)을 DB에서 우선 처리.
  2.  DB에서 답변을 못 찾을 경우에만 `get_gpt_response` (RAG) 호출.
- **RAG 품질 개선:**
  - `policy_collection` 검색 시 `similarity_threshold`를 0.7로 상향 조정하여 관련성 낮은 컨텍스트 필터링.
  - `gpt_prompt_profile.json`의 `system_template`을 단순화하고 Markdown 사용을 명시적으로 지시하여 출력 형식 개선.
- **프론트엔드 `ChatInterface.vue` 수정:**
  - `loadChatHistory`에서 DB로부터 받은 `response_json` (문자열)을 파싱하여 객체로 변환.
  - 실시간 메시지와 채팅 기록의 데이터 구조를 통일하여, 이전 대화에서도 직원 정보 테이블 등이 정상적으로 렌더링되도록 버그 수정.
- **백엔드 DB 핸들링 수정:**
  - `mysql.connector`의 `DictCursor` 사용으로 인해 발생한 `KeyError: 0` 버그 수정.
  - DB 결과 접근 시 숫자 인덱스(`row[0]`) 대신 컬럼명(`row['id']`)을 사용하도록 코드 수정.

## 다음 단계
- 현재까지의 변경사항을 `memory-bank`에 종합적으로 업데이트. (진행 중)
- RAG 파이프라인의 전반적인 성능 및 안정성 테스트.
- 사용자 피드백을 기반으로 추가적인 프롬프트 튜닝 또는 검색 로직 개선 검토.

## 활성화된 결정사항과 고려사항
- **순차적 응답 전략:** "빠른 DB 검색 -> 실패 시 포괄적인 RAG" 전략을 유지하여 응답 효율성과 품질을 모두 확보.
- **엄격한 컨텍스트 필터링:** 관련성 낮은 정보를 LLM에 제공하는 것을 막기 위해 유사도 임계값을 엄격하게 유지. 이는 "Garbage In, Garbage Out" 문제를 방지하는 핵심 요소.
- **데이터 구조 일관성:** 프론트엔드와 백엔드, 실시간 데이터와 저장된 데이터 간의 자료 구조는 항상 일관되게 유지되어야 함.

## 미해결 질문
- 현재 RAG 파이프라인의 임계값(0.7)이 모든 종류의 정책 문서 질문에 대해 최적인가? 추가적인 튜닝이 필요한가?
- 장기적으로 `chatbot_collection`과 `policy_collection` 외에 추가 데이터 소스를 통합할 경우 현재의 2단계 파이프라인을 어떻게 확장할 것인가?

## 현재 작업 중인 기능

1. 프론트엔드 대시보드/위젯 UI/UX 개선 및 기능 확장
2. 위젯별 데이터 시뮬레이션/애니메이션/새로고침 등 세부 기능 강화

## 현재 고려사항

1. 코드 품질
   - 일관된 코딩 스타일 유지
   - 테스트 커버리지 확보
   - 문서화 강화

2. 보안
   - 환경 변수 관리
   - API 보안
   - 데이터 보호

3. 성능
   - 캐싱 전략
   - 데이터베이스 최적화
   - 응답 시간 개선

## 참고사항
- 이 문서는 현재 작업 상황을 반영하도록 자주 업데이트하세요
- 현재 상황과 결정사항에 집중하세요

## 랭체인 및 벡터DB 구조 Q&A (2024-06-05)

### 1. 테이블형 vector(DB)와 cromadb형 vector를 나누는 게 좋은가?
- 업무/서비스 로직(intents, patterns, responses, routes, widget 등)은 DB 기반 벡터로 관리
- 사내 문서 등 비정형 데이터는 ChromaDB 등 별도 벡터DB로 관리
- **정형(업무) vs 비정형(문서) 분리 유지가 유지보수, 확장성, 보안에 유리**

### 2. 랭체인 기반 ChromaDB 벡터 생성 시 카테고리 등 메타데이터로 LLM에 특정 카테고리 데이터만 전달 가능?
- LangChain VectorStore(Chroma 등)는 메타데이터 필드 지원
- 문서 임베딩 시 카테고리 등 메타데이터 저장, 검색/LLM 연동 시 필터링 가능
- **카테고리 등으로 원하는 문서만 LLM에 전달하는 것이 완벽하게 가능**

### 3. 특정 카테고리는 유사검색어 검색할 때만 참고할 수 있는지?
- 검색 시 메타데이터 필터로 특정 카테고리만 대상으로 유사도 검색 가능
- 쿼리 분석 → 카테고리 추출 → 해당 카테고리만 검색/LLM 컨텍스트로 활용 가능
- **랭체인 Retriever, VectorStore, LLMChain 등에서 메타데이터 기반 필터링은 표준적이고 강력한 기능**

---

**정리:**
- DB 벡터(정형, 서비스 로직)와 ChromaDB 벡터(비정형, 문서 RAG)는 분리 유지 권장
- ChromaDB 벡터 생성 시 메타데이터(카테고리 등) 반드시 포함
- 특정 카테고리만 유사검색/LLM 컨텍스트로 활용하는 것도 랭체인에서 쉽게 구현 가능 

## 한글 검색 품질 및 LangChain 벡터 검색엔진 이점 Q&A (2024-06-05)

### 1. sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 vs LangChain 기반 벡터 검색엔진

- MiniLM-L12-v2는 다국어(한글 포함) 지원 임베딩 모델로, 한글도 기본 수준의 의미 임베딩 가능
- 한글 특화 모델이 아니므로, 복잡한 한글 문장/신조어/띄어쓰기 오류 등에는 의미 구분력이 다소 떨어질 수 있음
- 최신 LLM 기반 임베딩(OpenAI, Cohere, Upstage 등)에 비해 의미적 정밀도, 문맥 파악력은 낮음

### 2. LangChain 기반 벡터 검색엔진의 한글 검색 이점

- LangChain은 다양한 임베딩 모델 + 벡터DB + 검색 파이프라인을 조합하는 프레임워크
- OpenAI, Cohere, Upstage Solar 등 최신 한글 특화 임베딩 모델을 쉽게 교체/실험 가능
- 여러 임베딩 모델을 조합(하이브리드/멀티 임베딩)하여 검색 품질 극대화 가능
- 카테고리, 태그 등 메타데이터 기반 고급 검색 및 필터링 가능
- 검색 결과를 LLM(한글 지원)과 연동해 자연스러운 한글 요약, 정렬, 후처리 등 고도화 가능

### 3. 실제 한글 검색 품질 비교

| 구분 | MiniLM-L12-v2 단독 | LangChain 기반(최신 임베딩+검색엔진) |
|------|--------------------|--------------------------------------|
| 한글 의미 파악 | 보통(일상/간단 문장) | 매우 우수(최신 임베딩 활용 시) |
| 도메인 특화/신조어 | 약함 | 특화 모델/파인튜닝 가능 |
| 검색 품질 확장성 | 제한적 | 매우 유연(모델/DB/체인 교체) |
| 메타데이터 활용 | 불가 | 가능(카테고리, 태그 등) |
| 후처리/요약 | 불가 | 가능(LLM 연동) |

**정리:**
- LangChain 기반 벡터 검색엔진은 임베딩 모델 선택의 자유, 메타데이터 활용, 체인/후처리 등으로 한글 검색 품질을 MiniLM-L12-v2 단독 사용 대비 훨씬 더 높일 수 있음
- 최신 한글 특화 임베딩(OpenAI, Upstage, Cohere 등)과 결합하면 정확도, 다양성, 확장성 모두 압도적 

# 현재 작업 컨텍스트

## 진행 중인 작업
1. 채팅 검색 부분 유사도 강화
   - patterns 테이블에 domain, category, similarity_threshold 컬럼 추가
   - ChromaDB 검색 시 도메인/카테고리 기반 필터링 적용
   - 유사도 점수와 임계값 기반 필터링 구현

2. 프론트엔드 버튼 처리 로직 개선
   - route_type에 따른 버튼 처리 분기
   - link 타입: navigateTo 함수로 처리
   - widget 타입: showWidget 함수로 처리

## 향후 구현 예정 기능
1. 추천 검색어 기능
   - patterns 테이블 활용하여 도메인/카테고리별 추천 검색어 제공
   - DB 검색 방식 채택 (벡터 검색 대비 장점):
     * 정확한 도메인/카테고리 기반 필터링
     * 패턴 우선순위/순서 제어 가능
     * 메타데이터 활용한 정교한 필터링
     * 빠른 응답 시간
   - 구현 방안:
     * patterns 테이블에 is_recommended, recommended_order 컬럼 추가
     * 도메인/카테고리별 추천 검색어 조회 API 구현
     * 추천 검색어 선택 시 해당 패턴으로 검색 수행

## 최근 변경사항
1. 2024-06-14: 채팅 검색 유사도 강화
   - patterns 테이블 구조 변경
   - ChromaDB 검색 로직 개선
   - 도메인/카테고리 기반 필터링 적용

2. 2024-06-14: 프론트엔드 버튼 처리 개선
   - route_type 기반 버튼 처리 분기 구현
   - link/widget 타입에 따른 적절한 핸들러 적용

## 현재 이슈
1. ChromaDB 검색 결과 품질 개선 필요
   - 도메인/카테고리 기반 필터링 적용
   - 유사도 점수와 임계값 기반 필터링
   - 벡터 품질 개선 필요

2. response_handler 관련 버그
   - route_type이 "link"인데 response_handler가 설정된 경우 발생
   - responses 테이블의 데이터 정리 필요
   - 월요일(2024-06-17) 수정 예정

## 다음 단계
1. 추천 검색어 기능 구현 준비
   - patterns 테이블 스키마 변경
   - 추천 검색어 조회 API 설계
   - 프론트엔드 연동 방안 검토

2. response_handler 버그 수정
   - responses 테이블 데이터 정리
   - route_type과 response_handler 관계 명확화
   - 테스트 케이스 작성 

## 기술 참고사항 (LLM연동)

### ChromaContext를 User Role에 포함하는 이유

1. **맥락의 명확성**
   - `system` 프롬프트는 AI의 역할과 행동 지침을 정의하는 용도
   - `user` 메시지는 실제 질문과 그에 대한 참고 자료를 포함
   - `chroma_context`는 사용자의 질문에 대한 참고 자료이므로 `user` 메시지에 포함하는 것이 더 자연스러움

2. **GPT의 이해도 향상**
   - GPT는 `user` 메시지의 내용을 "사용자가 제공한 정보"로 인식
   - `chroma_context`를 `user` 메시지에 포함함으로써, GPT는 이를 "사용자가 참고하라고 제공한 정책 정보"로 이해
   - 이는 GPT가 정책 정보를 더 자연스럽게 활용하도록 도움

3. **대화 흐름의 자연스러움**
   - 실제 대화에서는 사용자가 질문할 때 관련 자료를 함께 제시하는 것이 자연스러움
   - `user` 메시지에 `chroma_context`를 포함함으로써 더 자연스러운 대화 흐름 구현

4. **시스템 프롬프트의 역할 분리**
   - `system` 프롬프트는 AI의 행동 지침에 집중
   - 실제 대화 내용과 참고 자료는 `user` 메시지에 포함
   - 이는 역할과 책임의 명확한 분리

따라서 `chroma_context`를 `user` role의 메시지에 포함시키는 것이 더 적절한 구조라고 판단됩니다. 

### GPT Function Calling 처리 방식

1. **Function 정의**
   - GPT에 전달할 함수들을 JSON 스키마 형태로 정의
   - 함수명, 설명, 파라미터 타입과 설명 포함
   - 필수 파라미터 지정 가능

2. **Function Calling 흐름**
   - GPT 호출 시 functions 파라미터로 함수 정의 전달
   - GPT가 function_call을 반환하면 해당 함수 실행
   - 함수 실행 결과를 다시 GPT에 전달하여 최종 응답 생성

3. **구현 시 주의사항**
   - 함수 정의는 명확하고 구체적으로 작성
   - 필수 파라미터와 선택적 파라미터 구분
   - 함수 실행 결과는 JSON 형식으로 직렬화
   - 에러 처리와 로깅 철저히 구현

4. **장점**
   - GPT가 외부 함수를 호출하여 동적 데이터 조회 가능
   - 구조화된 데이터 처리 가능
   - 비즈니스 로직과 GPT 응답 생성 분리
   - 확장성과 유지보수성 향상 

### GPT 프롬프트 프로필 관리

1. **프로필 구조**
   - JSON 기반의 프로필 정의
   - role과 rules로 구성된 구조화된 프롬프트
   - 여러 프로필 유형 지원 (policy, HR, general 등)

2. **프로필 관리 방식**
   - `/core/profiles/gpt_prompt_profile.json`에서 중앙 관리
   - 유틸리티 함수를 통한 프로필 로드 및 포맷팅
   - 코드와 프롬프트 내용의 분리

3. **장점**
   - 프롬프트 관리 용이성 향상
   - 프로필 재사용 가능
   - 유연한 프로필 전환
   - 유지보수성 개선

4. **사용 예시**
   ```python
   # 프로필 로드
   system_prompt = format_system_prompt("policy_assistant")
   
   # 사용 가능한 프로필 확인
   profiles = get_available_profiles()
   ``` 